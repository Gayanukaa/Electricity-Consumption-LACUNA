{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gayanuka Amarasuriya\\AppData\\Local\\Temp\\ipykernel_11804\\44952568.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(file) for file in all_files]\n",
      "C:\\Users\\Gayanuka Amarasuriya\\AppData\\Local\\Temp\\ipykernel_11804\\44952568.py:4: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(file) for file in all_files]\n"
     ]
    }
   ],
   "source": [
    "# Function to load multiple CSV files into a single DataFrame\n",
    "def load_multiple_csv(folder_path):\n",
    "    all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "#%%\n",
    "# Define folder paths for Smart Meter and Non-Smart Meter data\n",
    "smart_meter_folder = r\"data\\EC2\\smart_meter_data\"\n",
    "non_smart_meter_file = r\"data\\EC2\\non_smart_meter_data.csv\"\n",
    "\n",
    "# Load Smart Meter data\n",
    "smart_meter_data = load_multiple_csv(smart_meter_folder)\n",
    "\n",
    "# Load Non-Smart Meter data\n",
    "non_smart_meter_data = pd.read_csv(non_smart_meter_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gayanuka Amarasuriya\\AppData\\Local\\Temp\\ipykernel_11804\\2646075150.py:8: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  room_roster = pd.read_csv('data\\EC1\\w1_room_roster.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load EC1 supporting datasets\n",
    "demographics = pd.read_csv('data\\EC1\\w1_demographics.csv')\n",
    "appliances = pd.read_csv('data\\EC1\\w1_appliances.csv')\n",
    "electricity_gen = pd.read_csv('data\\EC1\\w1_electricity_generation_water_heating_cooking.csv')\n",
    "fan_roster = pd.read_csv('data\\EC1\\w1_fan_roster.csv')\n",
    "household_info = pd.read_csv('data\\EC1\\w1_household_information_and_history.csv')\n",
    "light_roster = pd.read_csv('data\\EC1\\w1_light_roster.csv')\n",
    "room_roster = pd.read_csv('data\\EC1\\w1_room_roster.csv')\n",
    "\n",
    "#%%\n",
    "# Merge supporting datasets into one\n",
    "ec1_data = pd.concat([demographics, appliances, electricity_gen, fan_roster, household_info, light_roster, room_roster], axis=1)\n",
    "\n",
    "# Ensure 'Month' column exists in both DataFrames\n",
    "if 'Month' not in smart_meter_data.columns:\n",
    "    smart_meter_data['Month'] = np.nan  # or any default value\n",
    "\n",
    "if 'Month' not in non_smart_meter_data.columns:\n",
    "    non_smart_meter_data['Month'] = np.nan  # or any default value\n",
    "\n",
    "# Combine Smart and Non-Smart Meter Data\n",
    "combined_data = pd.merge(smart_meter_data, non_smart_meter_data, on=['household_ID', 'Month'], how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    'TR1_TOTAL_IMPORT (kWh)', 'TR2_TOTAL_IMPORT (kWh)',\n",
    "    'TR3_TOTAL_IMPORT (kWh)', 'TOTAL_IMPORT (kWh)', 'TOTAL_EXPORT (kWh)'\n",
    "]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    combined_data[col] = pd.to_numeric(combined_data[col], errors='coerce')\n",
    "\n",
    "# Derive new metrics\n",
    "combined_data['day_peak_ratio'] = combined_data['TR1_TOTAL_IMPORT (kWh)'] / combined_data['TR2_TOTAL_IMPORT (kWh)']\n",
    "combined_data['off_peak_efficiency'] = combined_data['TR3_TOTAL_IMPORT (kWh)'] / combined_data['TOTAL_IMPORT (kWh)']\n",
    "combined_data['generation_consumption_ratio'] = combined_data['TOTAL_EXPORT (kWh)'] / combined_data['TOTAL_IMPORT (kWh)']\n",
    "\n",
    "# Handle missing or infinite values resulting from derived metrics\n",
    "combined_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "combined_data.dropna(subset=['day_peak_ratio', 'off_peak_efficiency', 'generation_consumption_ratio'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data for clustering\n",
    "features = ['day_peak_ratio', 'off_peak_efficiency', 'generation_consumption_ratio']\n",
    "scaler = StandardScaler()\n",
    "combined_data_scaled = scaler.fit_transform(combined_data[features])\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization\n",
    "combined_data_pca = pca.fit_transform(combined_data_scaled)\n",
    "\n",
    "#%%\n",
    "# Apply KMeans Clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "combined_data['cluster'] = kmeans.fit_predict(combined_data_pca)\n",
    "\n",
    "# Determine efficiency boundaries\n",
    "cluster_centers = scaler.inverse_transform(pca.inverse_transform(kmeans.cluster_centers_))\n",
    "combined_data['efficiency_status'] = combined_data['cluster'].apply(lambda x: 'efficient' if x == np.argmax(cluster_centers[:, 1]) else 'inefficient')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Clustering (PCA Components)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster in range(3):\n",
    "    subset = combined_data[combined_data['cluster'] == cluster]\n",
    "    plt.scatter(combined_data_pca[combined_data['cluster'] == cluster, 0],\n",
    "                combined_data_pca[combined_data['cluster'] == cluster, 1],\n",
    "                label=f'Cluster {cluster}')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Clustering with PCA Components')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate clustering\n",
    "sil_score = silhouette_score(combined_data_pca, combined_data['cluster'])\n",
    "print(f\"Silhouette Score: {sil_score}\")\n",
    "\n",
    "# Identify inefficient households\n",
    "inefficient_households = combined_data[combined_data['efficiency_status'] == 'inefficient']\n",
    "print(f\"Number of Inefficient Households: {inefficient_households.shape[0]}\")\n",
    "print(inefficient_households[['household_ID', 'efficiency_status']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
